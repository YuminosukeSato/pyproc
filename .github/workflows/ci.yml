name: CI

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ "**" ]

permissions:
  contents: read

jobs:
  go:
    name: Go build, lint, test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod
          cache: true

      - name: Go fmt check
        run: |
          fmt_out=$(gofmt -l . || true)
          if [ -n "$fmt_out" ]; then
            echo "Run 'go fmt' on the following files:" >&2
            echo "$fmt_out" >&2
            exit 1
          fi

      - name: Go vet
        shell: bash
        run: |
          set -euo pipefail
          pkgs=$(go list ./... | grep -v '/bench')
          if [ -n "$pkgs" ]; then
            echo "$pkgs" | xargs -r -n1 go vet
          fi

      - name: Build all packages
        shell: bash
        run: |
          set -euo pipefail
          pkgs=$(go list ./... | grep -v '/bench')
          if [ -n "$pkgs" ]; then
            echo "$pkgs" | xargs -r -n1 go build
          fi

      - name: Build examples
        run: go build ./examples/basic

      - name: golangci-lint
        uses: golangci/golangci-lint-action@v6
        with:
          version: latest
          args: --timeout=5m

      - name: Test
        shell: bash
        run: |
          set -euo pipefail
          pkgs=$(go list ./... | grep -v '/bench')
          if [ -n "$pkgs" ]; then
            echo "$pkgs" | xargs -r -n1 go test -timeout 5m -v -race
          fi

  python:
    name: Python lint and tests (uv)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: worker/python
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup uv and Python
        uses: astral-sh/setup-uv@v4

      - name: Sync dependencies
        run: uv sync --all-extras --dev

      - name: Ruff check
        run: uv run ruff check .

      - name: Ruff format check
        run: uv run ruff format --check .

      - name: Pytest
        run: uv run pytest -q

  benchmark:
    name: Performance benchmarks and gates
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod
          cache: true

      - name: Setup Python with uv
        uses: astral-sh/setup-uv@v4

      - name: Install Python dependencies
        run: |
          cd worker/python
          uv sync --all-extras

      - name: Run benchmarks
        run: |
          cd bench
          go test -bench=BenchmarkLatencyPercentiles -benchmem -benchtime=10s -timeout=5m | tee benchmark_results.txt || true
          
          # Extract and check performance metrics
          if grep -q "p50:" benchmark_results.txt; then
            echo "=== Performance Results ==="
            grep -E "p50:|p95:|p99:" benchmark_results.txt
            
            # Extract p50 value (in microseconds)
            p50=$(grep "p50:" benchmark_results.txt | sed -E 's/.*p50: ([0-9.]+).*/\1/')
            p99=$(grep "p99:" benchmark_results.txt | sed -E 's/.*p99: ([0-9.]+).*/\1/')
            
            echo ""
            echo "Checking performance gates..."
            
            # Check p50 < 100µs
            if [ ! -z "$p50" ]; then
              if (( $(echo "$p50 > 100" | bc -l) )); then
                echo "⚠️  p50 latency ${p50}µs exceeds target of 100µs (non-blocking)"
              else
                echo "✅ p50 latency ${p50}µs meets target (<100µs)"
              fi
            fi
            
            # Check p99 < 500µs
            if [ ! -z "$p99" ]; then
              if (( $(echo "$p99 > 500" | bc -l) )); then
                echo "⚠️  p99 latency ${p99}µs exceeds target of 500µs (non-blocking)"
              else
                echo "✅ p99 latency ${p99}µs meets target (<500µs)"
              fi
            fi
          else
            echo "No latency metrics found in benchmark results"
          fi

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: bench/benchmark_results.txt

  links:
    name: README and docs link check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Link Checker
        uses: lycheeverse/lychee-action@v2
        with:
          args: --config .lychee.toml README.md "docs/**/*.md"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
